{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from coherenceModel import *\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>is_coherent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The preflight inspection of the fuel tanks by ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The pilot reported that he was cleared to 4,00...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The instrument-rated private pilot lost contro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The non-instrument rated private pilot was rec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The commercial pilot reported a partial power ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>The engine ran for approximately 30 minutes at...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>Examination of the wreckage revealed that ther...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>The engine then lost all power, and the pilot ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>During the approach, the pilot was able to res...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>A test run of the engine revealed that it expe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paragraph  is_coherent\n",
       "0      The preflight inspection of the fuel tanks by ...            1\n",
       "1      The pilot reported that he was cleared to 4,00...            1\n",
       "2      The instrument-rated private pilot lost contro...            1\n",
       "3      The non-instrument rated private pilot was rec...            1\n",
       "4      The commercial pilot reported a partial power ...            1\n",
       "...                                                  ...          ...\n",
       "41995  The engine ran for approximately 30 minutes at...            0\n",
       "41996  Examination of the wreckage revealed that ther...            0\n",
       "41997  The engine then lost all power, and the pilot ...            0\n",
       "41998  During the approach, the pilot was able to res...            0\n",
       "41999  A test run of the engine revealed that it expe...            0\n",
       "\n",
       "[42000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_df = pd.read_csv('moreAviationPerms.csv')\n",
    "paragraph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It had been consumed by fire after a collision with trees. The coroner was an FAA DME (designated medical examiner). The airplane was found three days after it was declared missing. He said he did not call the authorities because he did not hear a crash or see smoke. Examination of wreckage revealed no mechanical anomaly that would have prevented normal flight. A toxicology test and autopsy were inconclusive due to inadequate or unsuitable specimens. He said he had denied the accident pilot a medical certificate due to heart disease, but the pilot appealed his decision and was given a special medical certificate. Also, he said the weather was clear and sunny. He said it was at an altitude equal to other airplanes departing and arriving at the airport. A witness said he observed the airplane flying level near the departure airport. The witness said the airplane suddenly pitched down, descended below trees, and did not come back up.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    paragraph_df.paragraph.values, \n",
    "    paragraph_df.is_coherent.values,\n",
    "    stratify = paragraph_df.is_coherent.values,\n",
    "    test_size = 0.1, \n",
    "    random_state = 487\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    stratify = y_train,\n",
    "    test_size = 0.2, \n",
    "    random_state = 487\n",
    ")\n",
    "print(X_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "embed = gensim.downloader.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of coherent windows: 9912\n",
      "Number of incoherent windows: 200742\n",
      "Number of coherent windows: 2520\n",
      "Number of incoherent windows: 50217\n",
      "Number of coherent windows: 1399\n",
      "Number of incoherent windows: 27895\n"
     ]
    }
   ],
   "source": [
    "train_data = WindowedParDataset(X_train, y_train, embed, 5)\n",
    "dev_data = WindowedParDataset(X_val, y_val, embed, 5)\n",
    "test_data = WindowedParDataset(X_test, y_test, embed, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=25, collate_fn=basic_collate_fn, shuffle=True)\n",
    "dev_loader = DataLoader(dev_data, batch_size=25, collate_fn=basic_collate_fn, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=25, collate_fn=basic_collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pos = len(paragraph_df[paragraph_df[\"is_coherent\"] == 1])\n",
    "num_neg = len(paragraph_df[paragraph_df[\"is_coherent\"] == 0])\n",
    "dampen = 1\n",
    "pos_weight = torch.Tensor([num_neg / num_pos / dampen]).to(device)\n",
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Start Training ------------------------\n",
      "Epoch No. 1--Iteration No. 2110-- batch loss = 1.8297\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.0478\n",
      "Validation loss: 1.3249\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m ffnn\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m optim \u001b[38;5;241m=\u001b[39m get_optimizer(ffnn, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-1\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m best_model, stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mffnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollect_cycle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m plot_loss(stats)\n",
      "File \u001b[0;32m~/class/487/project/coherenceModel.py:215\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(net, trn_loader, val_loader, optim, pos_weight, num_epoch, collect_cycle, device, verbose, patience, stopping_criteria)\u001b[0m\n\u001b[1;32m    213\u001b[0m             output \u001b[38;5;241m=\u001b[39m net(windows)\n\u001b[1;32m    214\u001b[0m             loss \u001b[38;5;241m=\u001b[39m calculate_loss(output, labels, loss_fn)\n\u001b[0;32m--> 215\u001b[0m             \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m             optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m#             print_grads(net)\u001b[39;00m\n",
      "File \u001b[0;32m~/class/448/eecs448/lib/python3.8/site-packages/torch/_tensor.py:477\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    430\u001b[0m ):\n\u001b[1;32m    431\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m    The graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;124;03m            used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_torch_function_unary\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m             Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m             (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m             inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m         )\n\u001b[1;32m    487\u001b[0m     torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test on validation to see if overfit is possible\n",
    "ffnn = FFNN(5, device)\n",
    "ffnn.to(device)\n",
    "optim = get_optimizer(ffnn, lr=1e-2, weight_decay=0)\n",
    "best_model, stats = train_model(ffnn, dev_loader, dev_loader, optim, pos_weight=pos_weight,\n",
    "                                num_epoch=15, collect_cycle=20, device=device, patience=None)\n",
    "plot_loss(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "def get_sampler(X, y):\n",
    "    counts = [0, 0]\n",
    "    for l in y:\n",
    "        counts[l] += 1\n",
    "    sample_weights = [1 / counts[0], 1 / counts[1]]\n",
    "    print(sample_weights)\n",
    "    return WeightedRandomSampler(num_samples=len(X), weights=sample_weights, replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of coherent windows: 9938\n",
      "Number of incoherent windows: 200790\n",
      "Number of coherent windows: 2520\n",
      "Number of incoherent windows: 50221\n",
      "Number of coherent windows: 1399\n",
      "Number of incoherent windows: 27896\n"
     ]
    }
   ],
   "source": [
    "################ SET THIS TO CHANGE WINDOW SIZE OF THINGS BELOW:\n",
    "wsize = 5\n",
    "################\n",
    "train_data = WindowedParDataset(X_train, y_train, embed, wsize)\n",
    "dev_data = WindowedParDataset(X_val, y_val, embed, wsize)\n",
    "test_data = WindowedParDataset(X_test, y_test, embed, wsize)\n",
    "train_loader = DataLoader(train_data, batch_size=25, collate_fn=basic_collate_fn, shuffle=True)\n",
    "dev_loader = DataLoader(dev_data, batch_size=25, collate_fn=basic_collate_fn, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=25, collate_fn=basic_collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate from: [0.01]\n",
      "weight_decay from: [0.0002, 0.002, 0.005, 0.01, 0.02, 0.025, 0.04, 0.05, 0.1]\n",
      "window from: [5]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638f85735a3c4b3ba07fd176a7ddafd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------ Start Training ------------------------\n",
      "Epoch No. 1--Iteration No. 8430-- batch loss = 0.5011\n",
      "Validation UAR: 0.6831\n",
      "Validation accuracy: 0.6610\n",
      "Validation loss: 1.1516\n",
      "Epoch No. 2--Iteration No. 16860-- batch loss = 0.4586\n",
      "Validation UAR: 0.6941\n",
      "Validation accuracy: 0.7197\n",
      "Validation loss: 1.1206\n",
      "Epoch No. 3--Iteration No. 25290-- batch loss = 0.3654\n",
      "Validation UAR: 0.7113\n",
      "Validation accuracy: 0.7126\n",
      "Validation loss: 1.0954\n",
      "Epoch No. 4--Iteration No. 33720-- batch loss = 0.1224\n",
      "Validation UAR: 0.7217\n",
      "Validation accuracy: 0.7233\n",
      "Validation loss: 1.0623\n",
      "Epoch No. 5--Iteration No. 42150-- batch loss = 0.5738\n",
      "Validation UAR: 0.7360\n",
      "Validation accuracy: 0.7277\n",
      "Validation loss: 1.0376\n",
      "Epoch No. 6--Iteration No. 50580-- batch loss = 0.4922\n",
      "Validation UAR: 0.7415\n",
      "Validation accuracy: 0.7418\n",
      "Validation loss: 1.0135\n",
      "Epoch No. 7--Iteration No. 59010-- batch loss = 0.3734\n",
      "Validation UAR: 0.7402\n",
      "Validation accuracy: 0.7587\n",
      "Validation loss: 1.0033\n",
      "Epoch No. 8--Iteration No. 67440-- batch loss = 0.7519\n",
      "Validation UAR: 0.7478\n",
      "Validation accuracy: 0.7626\n",
      "Validation loss: 0.9902\n",
      "Epoch No. 9--Iteration No. 75870-- batch loss = 0.6597\n",
      "Validation UAR: 0.7483\n",
      "Validation accuracy: 0.7540\n",
      "Validation loss: 0.9875\n",
      "Epoch No. 10--Iteration No. 84300-- batch loss = 0.7262\n",
      "Validation UAR: 0.7512\n",
      "Validation accuracy: 0.7730\n",
      "Validation loss: 0.9787\n",
      "Epoch No. 11--Iteration No. 92730-- batch loss = 0.1059\n",
      "Validation UAR: 0.7546\n",
      "Validation accuracy: 0.7563\n",
      "Validation loss: 0.9661\n",
      "Epoch No. 12--Iteration No. 101160-- batch loss = 0.5342\n",
      "Validation UAR: 0.7464\n",
      "Validation accuracy: 0.7906\n",
      "Validation loss: 0.9815\n",
      "Epoch No. 13--Iteration No. 109590-- batch loss = 0.3229\n",
      "Validation UAR: 0.7444\n",
      "Validation accuracy: 0.8133\n",
      "Validation loss: 0.9924\n",
      "Epoch No. 14--Iteration No. 118020-- batch loss = 0.7402\n",
      "Validation UAR: 0.7591\n",
      "Validation accuracy: 0.7717\n",
      "Validation loss: 0.9518\n",
      "Epoch No. 15--Iteration No. 126450-- batch loss = 0.0547\n",
      "Validation UAR: 0.7539\n",
      "Validation accuracy: 0.7926\n",
      "Validation loss: 0.9721\n",
      "Epoch No. 16--Iteration No. 134880-- batch loss = 0.8122\n",
      "Validation UAR: 0.7526\n",
      "Validation accuracy: 0.7933\n",
      "Validation loss: 0.9708\n",
      "Epoch No. 17--Iteration No. 143310-- batch loss = 0.3806\n",
      "Validation UAR: 0.7399\n",
      "Validation accuracy: 0.8265\n",
      "Validation loss: 1.0135\n",
      "Epoch No. 18--Iteration No. 151740-- batch loss = 0.1348\n",
      "Validation UAR: 0.7563\n",
      "Validation accuracy: 0.7875\n",
      "Validation loss: 0.9706\n",
      "Epoch No. 19--Iteration No. 160170-- batch loss = 3.6504\n",
      "Validation UAR: 0.7591\n",
      "Validation accuracy: 0.7698\n",
      "Validation loss: 0.9610\n",
      "Training lasted 92.25 minutes\n",
      "------------------------ Training Done ------------------------\n",
      "(0.01, 0.0002, 5): 0.7591207102701298\n",
      "------------------------ Start Training ------------------------\n",
      "Epoch No. 1--Iteration No. 8430-- batch loss = 0.8249\n",
      "Validation UAR: 0.6306\n",
      "Validation accuracy: 0.5693\n",
      "Validation loss: 1.2315\n",
      "Epoch No. 2--Iteration No. 16860-- batch loss = 0.4903\n",
      "Validation UAR: 0.6681\n",
      "Validation accuracy: 0.5984\n",
      "Validation loss: 1.1683\n",
      "Epoch No. 3--Iteration No. 25290-- batch loss = 0.3695\n",
      "Validation UAR: 0.6848\n",
      "Validation accuracy: 0.6713\n",
      "Validation loss: 1.1476\n",
      "Epoch No. 4--Iteration No. 33720-- batch loss = 0.6068\n",
      "Validation UAR: 0.6895\n",
      "Validation accuracy: 0.6882\n",
      "Validation loss: 1.1292\n",
      "Epoch No. 5--Iteration No. 42150-- batch loss = 0.2973\n",
      "Validation UAR: 0.6985\n",
      "Validation accuracy: 0.6753\n",
      "Validation loss: 1.1079\n",
      "Epoch No. 6--Iteration No. 50580-- batch loss = 5.7470\n",
      "Validation UAR: 0.7032\n",
      "Validation accuracy: 0.6493\n",
      "Validation loss: 1.0973\n",
      "Epoch No. 7--Iteration No. 59010-- batch loss = 0.7988\n",
      "Validation UAR: 0.7009\n",
      "Validation accuracy: 0.7240\n",
      "Validation loss: 1.0976\n",
      "Epoch No. 8--Iteration No. 67440-- batch loss = 0.6904\n",
      "Validation UAR: 0.7079\n",
      "Validation accuracy: 0.7359\n",
      "Validation loss: 1.0833\n",
      "Epoch No. 9--Iteration No. 75870-- batch loss = 0.5221\n",
      "Validation UAR: 0.7139\n",
      "Validation accuracy: 0.7178\n",
      "Validation loss: 1.0727\n",
      "Epoch No. 10--Iteration No. 84300-- batch loss = 0.6665\n",
      "Validation UAR: 0.7207\n",
      "Validation accuracy: 0.7211\n",
      "Validation loss: 1.0564\n",
      "Epoch No. 11--Iteration No. 92730-- batch loss = 0.9747\n",
      "Validation UAR: 0.7212\n",
      "Validation accuracy: 0.7478\n",
      "Validation loss: 1.0502\n",
      "Epoch No. 12--Iteration No. 101160-- batch loss = 0.6300\n",
      "Validation UAR: 0.7260\n",
      "Validation accuracy: 0.6461\n",
      "Validation loss: 1.0361\n",
      "Epoch No. 13--Iteration No. 109590-- batch loss = 0.8742\n",
      "Validation UAR: 0.7247\n",
      "Validation accuracy: 0.7509\n",
      "Validation loss: 1.0370\n",
      "Epoch No. 14--Iteration No. 118020-- batch loss = 0.6223\n",
      "Validation UAR: 0.7221\n",
      "Validation accuracy: 0.7723\n",
      "Validation loss: 1.0419\n",
      "Epoch No. 15--Iteration No. 126450-- batch loss = 0.1522\n",
      "Validation UAR: 0.7316\n",
      "Validation accuracy: 0.7211\n",
      "Validation loss: 1.0161\n",
      "Epoch No. 16--Iteration No. 134880-- batch loss = 0.4102\n",
      "Validation UAR: 0.7350\n",
      "Validation accuracy: 0.7049\n",
      "Validation loss: 1.0090\n",
      "Epoch No. 17--Iteration No. 143310-- batch loss = 0.6483\n",
      "Validation UAR: 0.7316\n",
      "Validation accuracy: 0.7648\n",
      "Validation loss: 1.0145\n",
      "Epoch No. 18--Iteration No. 151740-- batch loss = 2.6315\n",
      "Validation UAR: 0.7219\n",
      "Validation accuracy: 0.7370\n",
      "Validation loss: 1.0273\n",
      "Epoch No. 19--Iteration No. 160170-- batch loss = 1.0118\n",
      "Validation UAR: 0.7362\n",
      "Validation accuracy: 0.7263\n",
      "Validation loss: 0.9984\n",
      "Epoch No. 20--Iteration No. 168600-- batch loss = 0.5990\n",
      "Validation UAR: 0.7339\n",
      "Validation accuracy: 0.7659\n",
      "Validation loss: 1.0047\n",
      "Epoch No. 21--Iteration No. 177030-- batch loss = 0.5706\n",
      "Validation UAR: 0.7405\n",
      "Validation accuracy: 0.7462\n",
      "Validation loss: 1.0013\n",
      "Epoch No. 22--Iteration No. 185460-- batch loss = 0.1011\n",
      "Validation UAR: 0.7431\n",
      "Validation accuracy: 0.7423\n",
      "Validation loss: 0.9908\n",
      "Epoch No. 23--Iteration No. 193890-- batch loss = 0.5118\n",
      "Validation UAR: 0.7443\n",
      "Validation accuracy: 0.7327\n",
      "Validation loss: 0.9909\n",
      "Epoch No. 24--Iteration No. 202320-- batch loss = 0.5748\n",
      "Validation UAR: 0.7394\n",
      "Validation accuracy: 0.7664\n",
      "Validation loss: 0.9946\n",
      "Epoch No. 25--Iteration No. 210750-- batch loss = 0.6545\n",
      "Validation UAR: 0.7442\n",
      "Validation accuracy: 0.7077\n",
      "Validation loss: 0.9815\n",
      "Epoch No. 26--Iteration No. 219180-- batch loss = 0.2266\n",
      "Validation UAR: 0.7459\n",
      "Validation accuracy: 0.7411\n",
      "Validation loss: 0.9826\n",
      "Epoch No. 27--Iteration No. 227610-- batch loss = 0.7873\n",
      "Validation UAR: 0.7456\n",
      "Validation accuracy: 0.7276\n",
      "Validation loss: 0.9792\n",
      "Epoch No. 28--Iteration No. 236040-- batch loss = 0.3821\n",
      "Validation UAR: 0.7445\n",
      "Validation accuracy: 0.7337\n",
      "Validation loss: 0.9804\n",
      "Epoch No. 29--Iteration No. 244470-- batch loss = 0.3581\n",
      "Validation UAR: 0.7389\n",
      "Validation accuracy: 0.7561\n",
      "Validation loss: 0.9900\n",
      "Epoch No. 30--Iteration No. 252900-- batch loss = 0.1516\n",
      "Validation UAR: 0.7415\n",
      "Validation accuracy: 0.7650\n",
      "Validation loss: 0.9905\n",
      "Epoch No. 31--Iteration No. 261330-- batch loss = 0.1193\n",
      "Validation UAR: 0.7311\n",
      "Validation accuracy: 0.7811\n",
      "Validation loss: 1.0174\n",
      "Training lasted 167.61 minutes\n",
      "------------------------ Training Done ------------------------\n",
      "(0.01, 0.002, 5): 0.745908453682343\n",
      "------------------------ Start Training ------------------------\n",
      "Epoch No. 1--Iteration No. 8430-- batch loss = 0.7459\n",
      "Validation UAR: 0.6023\n",
      "Validation accuracy: 0.6241\n",
      "Validation loss: 1.2613\n",
      "Epoch No. 2--Iteration No. 16860-- batch loss = 0.7244\n",
      "Validation UAR: 0.6092\n",
      "Validation accuracy: 0.6667\n",
      "Validation loss: 1.2504\n",
      "Epoch No. 3--Iteration No. 25290-- batch loss = 0.4768\n",
      "Validation UAR: 0.6180\n",
      "Validation accuracy: 0.6358\n",
      "Validation loss: 1.2401\n",
      "Epoch No. 4--Iteration No. 33720-- batch loss = 0.5700\n",
      "Validation UAR: 0.6279\n",
      "Validation accuracy: 0.5516\n",
      "Validation loss: 1.2345\n",
      "Epoch No. 5--Iteration No. 42150-- batch loss = 0.5533\n",
      "Validation UAR: 0.6434\n",
      "Validation accuracy: 0.6378\n",
      "Validation loss: 1.2108\n",
      "Epoch No. 6--Iteration No. 50580-- batch loss = 0.4515\n",
      "Validation UAR: 0.6474\n",
      "Validation accuracy: 0.6268\n",
      "Validation loss: 1.2037\n",
      "Epoch No. 7--Iteration No. 59010-- batch loss = 0.7944\n",
      "Validation UAR: 0.6643\n",
      "Validation accuracy: 0.6712\n",
      "Validation loss: 1.1865\n",
      "Epoch No. 8--Iteration No. 67440-- batch loss = 9.9914\n",
      "Validation UAR: 0.6609\n",
      "Validation accuracy: 0.5846\n",
      "Validation loss: 1.1798\n",
      "Epoch No. 9--Iteration No. 75870-- batch loss = 0.5512\n",
      "Validation UAR: 0.6718\n",
      "Validation accuracy: 0.7084\n",
      "Validation loss: 1.1748\n",
      "Epoch No. 10--Iteration No. 84300-- batch loss = 0.9505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation UAR: 0.6712\n",
      "Validation accuracy: 0.6530\n",
      "Validation loss: 1.1692\n",
      "Epoch No. 11--Iteration No. 92730-- batch loss = 0.7569\n",
      "Validation UAR: 0.6840\n",
      "Validation accuracy: 0.6739\n",
      "Validation loss: 1.1445\n",
      "Epoch No. 12--Iteration No. 101160-- batch loss = 0.5702\n",
      "Validation UAR: 0.6895\n",
      "Validation accuracy: 0.6710\n",
      "Validation loss: 1.1357\n",
      "Epoch No. 13--Iteration No. 109590-- batch loss = 3.9095\n",
      "Validation UAR: 0.6936\n",
      "Validation accuracy: 0.6928\n",
      "Validation loss: 1.1260\n",
      "Epoch No. 14--Iteration No. 118020-- batch loss = 0.6763\n",
      "Validation UAR: 0.6879\n",
      "Validation accuracy: 0.6966\n",
      "Validation loss: 1.1316\n",
      "Epoch No. 15--Iteration No. 126450-- batch loss = 0.5887\n",
      "Validation UAR: 0.6973\n",
      "Validation accuracy: 0.7021\n",
      "Validation loss: 1.1128\n",
      "Epoch No. 16--Iteration No. 134880-- batch loss = 0.8481\n",
      "Validation UAR: 0.7010\n",
      "Validation accuracy: 0.6739\n",
      "Validation loss: 1.1045\n",
      "Epoch No. 17--Iteration No. 143310-- batch loss = 0.6534\n",
      "Validation UAR: 0.6980\n",
      "Validation accuracy: 0.6133\n",
      "Validation loss: 1.1064\n",
      "Epoch No. 18--Iteration No. 151740-- batch loss = 0.4591\n",
      "Validation UAR: 0.7007\n",
      "Validation accuracy: 0.7135\n",
      "Validation loss: 1.0976\n",
      "Epoch No. 19--Iteration No. 160170-- batch loss = 3.7968\n",
      "Validation UAR: 0.6987\n",
      "Validation accuracy: 0.6462\n",
      "Validation loss: 1.1006\n",
      "Epoch No. 20--Iteration No. 168600-- batch loss = 0.5360\n",
      "Validation UAR: 0.7090\n",
      "Validation accuracy: 0.6784\n",
      "Validation loss: 1.0823\n",
      "Epoch No. 21--Iteration No. 177030-- batch loss = 0.5578\n",
      "Validation UAR: 0.7004\n",
      "Validation accuracy: 0.7597\n",
      "Validation loss: 1.0919\n",
      "Epoch No. 22--Iteration No. 185460-- batch loss = 0.5198\n",
      "Validation UAR: 0.7082\n",
      "Validation accuracy: 0.7102\n",
      "Validation loss: 1.0745\n",
      "Epoch No. 23--Iteration No. 193890-- batch loss = 3.3293\n",
      "Validation UAR: 0.7050\n",
      "Validation accuracy: 0.6524\n",
      "Validation loss: 1.0832\n",
      "Epoch No. 24--Iteration No. 202320-- batch loss = 0.5753\n",
      "Validation UAR: 0.7124\n",
      "Validation accuracy: 0.7092\n",
      "Validation loss: 1.0670\n",
      "Epoch No. 25--Iteration No. 210750-- batch loss = 0.7501\n",
      "Validation UAR: 0.7109\n",
      "Validation accuracy: 0.6679\n",
      "Validation loss: 1.0703\n",
      "Epoch No. 26--Iteration No. 219180-- batch loss = 0.3010\n",
      "Validation UAR: 0.7143\n",
      "Validation accuracy: 0.7086\n",
      "Validation loss: 1.0694\n",
      "Epoch No. 27--Iteration No. 227610-- batch loss = 0.9702\n",
      "Validation UAR: 0.7148\n",
      "Validation accuracy: 0.7278\n",
      "Validation loss: 1.0587\n",
      "Epoch No. 28--Iteration No. 236040-- batch loss = 0.4195\n",
      "Validation UAR: 0.7162\n",
      "Validation accuracy: 0.7251\n",
      "Validation loss: 1.0564\n",
      "Epoch No. 29--Iteration No. 244470-- batch loss = 10.7929\n",
      "Validation UAR: 0.7157\n",
      "Validation accuracy: 0.6790\n",
      "Validation loss: 1.0523\n",
      "Epoch No. 30--Iteration No. 252900-- batch loss = 1.0831\n",
      "Validation UAR: 0.7178\n",
      "Validation accuracy: 0.6980\n",
      "Validation loss: 1.0489\n",
      "Epoch No. 31--Iteration No. 261330-- batch loss = 0.9456\n",
      "Validation UAR: 0.7150\n",
      "Validation accuracy: 0.6992\n",
      "Validation loss: 1.0489\n",
      "Epoch No. 32--Iteration No. 269760-- batch loss = 0.3763\n",
      "Validation UAR: 0.7149\n",
      "Validation accuracy: 0.7430\n",
      "Validation loss: 1.0515\n",
      "Epoch No. 33--Iteration No. 278190-- batch loss = 4.4820\n",
      "Validation UAR: 0.7203\n",
      "Validation accuracy: 0.7031\n",
      "Validation loss: 1.0409\n",
      "Epoch No. 34--Iteration No. 286620-- batch loss = 0.2451\n",
      "Validation UAR: 0.7221\n",
      "Validation accuracy: 0.7382\n",
      "Validation loss: 1.0398\n",
      "Epoch No. 35--Iteration No. 295050-- batch loss = 3.1743\n",
      "Validation UAR: 0.7150\n",
      "Validation accuracy: 0.6628\n",
      "Validation loss: 1.0475\n",
      "Epoch No. 36--Iteration No. 303480-- batch loss = 0.7065\n",
      "Validation UAR: 0.7220\n",
      "Validation accuracy: 0.7172\n",
      "Validation loss: 1.0341\n",
      "Epoch No. 37--Iteration No. 311910-- batch loss = 1.0590\n",
      "Validation UAR: 0.7200\n",
      "Validation accuracy: 0.7420\n",
      "Validation loss: 1.0400\n",
      "Epoch No. 38--Iteration No. 320340-- batch loss = 1.0150\n",
      "Validation UAR: 0.7208\n",
      "Validation accuracy: 0.7443\n",
      "Validation loss: 1.0412\n",
      "Epoch No. 39--Iteration No. 328770-- batch loss = 0.7949\n",
      "Validation UAR: 0.7217\n",
      "Validation accuracy: 0.7269\n",
      "Validation loss: 1.0306\n",
      "Training lasted 341.29 minutes\n",
      "------------------------ Training Done ------------------------\n",
      "(0.01, 0.005, 5): 0.7221373394674901\n",
      "------------------------ Start Training ------------------------\n",
      "Epoch No. 1--Iteration No. 8430-- batch loss = 4.5890\n",
      "Validation UAR: 0.5953\n",
      "Validation accuracy: 0.5436\n",
      "Validation loss: 1.2652\n",
      "Epoch No. 2--Iteration No. 16860-- batch loss = 0.6341\n",
      "Validation UAR: 0.5988\n",
      "Validation accuracy: 0.6232\n",
      "Validation loss: 1.2677\n",
      "Epoch No. 3--Iteration No. 25290-- batch loss = 0.6998\n",
      "Validation UAR: 0.6017\n",
      "Validation accuracy: 0.6578\n",
      "Validation loss: 1.2642\n",
      "Epoch No. 4--Iteration No. 33720-- batch loss = 0.7058\n",
      "Validation UAR: 0.5984\n",
      "Validation accuracy: 0.5801\n",
      "Validation loss: 1.2627\n",
      "Epoch No. 5--Iteration No. 42150-- batch loss = 2.9420\n",
      "Validation UAR: 0.5978\n",
      "Validation accuracy: 0.5753\n",
      "Validation loss: 1.2588\n",
      "Epoch No. 6--Iteration No. 50580-- batch loss = 0.5289\n",
      "Validation UAR: 0.6013\n",
      "Validation accuracy: 0.5734\n",
      "Validation loss: 1.2610\n",
      "Epoch No. 7--Iteration No. 59010-- batch loss = 0.8857\n",
      "Validation UAR: 0.6011\n",
      "Validation accuracy: 0.5680\n",
      "Validation loss: 1.2586\n",
      "Epoch No. 8--Iteration No. 67440-- batch loss = 0.6444\n",
      "Validation UAR: 0.5987\n",
      "Validation accuracy: 0.5569\n",
      "Validation loss: 1.2596\n",
      "Training lasted 47.35 minutes\n",
      "------------------------ Training Done ------------------------\n",
      "(0.01, 0.01, 5): 0.6017044346528029\n",
      "------------------------ Start Training ------------------------\n",
      "Epoch No. 1--Iteration No. 8430-- batch loss = 0.6997\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.0478\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 2--Iteration No. 16860-- batch loss = 0.6971\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.0478\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 3--Iteration No. 25290-- batch loss = 0.6950\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.0478\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 4--Iteration No. 33720-- batch loss = 0.6927\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 5--Iteration No. 42150-- batch loss = 0.6917\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3226\n",
      "Epoch No. 6--Iteration No. 50580-- batch loss = 0.6906\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 7--Iteration No. 59010-- batch loss = 0.6897\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 8--Iteration No. 67440-- batch loss = 0.6893\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3226\n",
      "Epoch No. 9--Iteration No. 75870-- batch loss = 0.6890\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 10--Iteration No. 84300-- batch loss = 5.1097\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 11--Iteration No. 92730-- batch loss = 0.6887\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 12--Iteration No. 101160-- batch loss = 0.6886\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 13--Iteration No. 109590-- batch loss = 0.6885\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 14--Iteration No. 118020-- batch loss = 0.6886\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 15--Iteration No. 126450-- batch loss = 0.6884\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3226\n",
      "Epoch No. 16--Iteration No. 134880-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 17--Iteration No. 143310-- batch loss = 5.1119\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 18--Iteration No. 151740-- batch loss = 5.1119\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 19--Iteration No. 160170-- batch loss = 5.1121\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 20--Iteration No. 168600-- batch loss = 0.6884\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 21--Iteration No. 177030-- batch loss = 0.6884\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 22--Iteration No. 185460-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No. 23--Iteration No. 193890-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3226\n",
      "Epoch No. 24--Iteration No. 202320-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 25--Iteration No. 210750-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 26--Iteration No. 219180-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 27--Iteration No. 227610-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 28--Iteration No. 236040-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 29--Iteration No. 244470-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3228\n",
      "Epoch No. 30--Iteration No. 252900-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 31--Iteration No. 261330-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 32--Iteration No. 269760-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 33--Iteration No. 278190-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3228\n",
      "Epoch No. 34--Iteration No. 286620-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 35--Iteration No. 295050-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 36--Iteration No. 303480-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 37--Iteration No. 311910-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 38--Iteration No. 320340-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 39--Iteration No. 328770-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 40--Iteration No. 337200-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 41--Iteration No. 345630-- batch loss = 0.6881\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 42--Iteration No. 354060-- batch loss = 0.6881\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 43--Iteration No. 362490-- batch loss = 0.6881\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 44--Iteration No. 370920-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3226\n",
      "Epoch No. 45--Iteration No. 379350-- batch loss = 9.5384\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 46--Iteration No. 387780-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 47--Iteration No. 396210-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 48--Iteration No. 404640-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 49--Iteration No. 413070-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 50--Iteration No. 421500-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3226\n",
      "Epoch No. 51--Iteration No. 429930-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Training lasted 324.80 minutes\n",
      "------------------------ Training Done ------------------------\n",
      "(0.01, 0.02, 5): 0.5\n",
      "------------------------ Start Training ------------------------\n",
      "Epoch No. 1--Iteration No. 8430-- batch loss = 0.6865\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3224\n",
      "Epoch No. 2--Iteration No. 16860-- batch loss = 0.6886\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 3--Iteration No. 25290-- batch loss = 0.6885\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 4--Iteration No. 33720-- batch loss = 5.1105\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 5--Iteration No. 42150-- batch loss = 5.1109\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 6--Iteration No. 50580-- batch loss = 0.6888\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 7--Iteration No. 59010-- batch loss = 0.6885\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 8--Iteration No. 67440-- batch loss = 5.1112\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 9--Iteration No. 75870-- batch loss = 0.6885\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 10--Iteration No. 84300-- batch loss = 0.6886\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 11--Iteration No. 92730-- batch loss = 5.1119\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 12--Iteration No. 101160-- batch loss = 0.6885\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 13--Iteration No. 109590-- batch loss = 0.6884\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 14--Iteration No. 118020-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 15--Iteration No. 126450-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 16--Iteration No. 134880-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 17--Iteration No. 143310-- batch loss = 0.6884\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 18--Iteration No. 151740-- batch loss = 0.6884\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3226\n",
      "Epoch No. 19--Iteration No. 160170-- batch loss = 0.6884\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3226\n",
      "Epoch No. 20--Iteration No. 168600-- batch loss = 0.6884\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 21--Iteration No. 177030-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 22--Iteration No. 185460-- batch loss = 5.1121\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3226\n",
      "Epoch No. 23--Iteration No. 193890-- batch loss = 0.6885\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 24--Iteration No. 202320-- batch loss = 0.6885\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3226\n",
      "Epoch No. 25--Iteration No. 210750-- batch loss = 0.6885\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 26--Iteration No. 219180-- batch loss = 0.6885\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 27--Iteration No. 227610-- batch loss = 0.6884\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 28--Iteration No. 236040-- batch loss = 5.1117\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 29--Iteration No. 244470-- batch loss = 0.6885\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 30--Iteration No. 252900-- batch loss = 0.6885\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 31--Iteration No. 261330-- batch loss = 0.6885\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3226\n",
      "Epoch No. 32--Iteration No. 269760-- batch loss = 0.6884\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No. 33--Iteration No. 278190-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 34--Iteration No. 286620-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 35--Iteration No. 295050-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 36--Iteration No. 303480-- batch loss = 0.6882\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3223\n",
      "Epoch No. 37--Iteration No. 311910-- batch loss = 5.1128\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 38--Iteration No. 320340-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 39--Iteration No. 328770-- batch loss = 0.6883\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 40--Iteration No. 337200-- batch loss = 5.1121\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 41--Iteration No. 345630-- batch loss = 5.1120\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 42--Iteration No. 354060-- batch loss = 0.6884\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 43--Iteration No. 362490-- batch loss = 0.6884\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3225\n",
      "Epoch No. 44--Iteration No. 370920-- batch loss = 0.6884\n",
      "Validation UAR: 0.5000\n",
      "Validation accuracy: 0.9522\n",
      "Validation loss: 1.3229\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m     plot_loss(best_stats)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model\n\u001b[0;32m---> 35\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m \u001b[43msearch_param_utterance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwsize\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 19\u001b[0m, in \u001b[0;36msearch_param_utterance\u001b[0;34m(wsize)\u001b[0m\n\u001b[1;32m     17\u001b[0m net \u001b[38;5;241m=\u001b[39m FFNN(window_size, device)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m optim \u001b[38;5;241m=\u001b[39m get_optimizer(net, lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mwd)\n\u001b[0;32m---> 19\u001b[0m model, stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollect_cycle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# print accuracy\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(lr,\u001b[38;5;250m \u001b[39mwd,\u001b[38;5;250m \u001b[39mwindow_size)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/class/487/project/coherenceModel.py:209\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(net, trn_loader, val_loader, optim, pos_weight, num_epoch, collect_cycle, device, verbose, patience, stopping_criteria)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m windows, labels \u001b[38;5;129;01min\u001b[39;00m trn_loader:\n\u001b[1;32m    208\u001b[0m     num_itr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 209\u001b[0m     windows \u001b[38;5;241m=\u001b[39m [[s\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m window] \u001b[38;5;28;01mfor\u001b[39;00m window \u001b[38;5;129;01min\u001b[39;00m windows]\n\u001b[1;32m    210\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    212\u001b[0m     optim\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/class/487/project/coherenceModel.py:209\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m windows, labels \u001b[38;5;129;01min\u001b[39;00m trn_loader:\n\u001b[1;32m    208\u001b[0m     num_itr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 209\u001b[0m     windows \u001b[38;5;241m=\u001b[39m [[s\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m window] \u001b[38;5;28;01mfor\u001b[39;00m window \u001b[38;5;129;01min\u001b[39;00m windows]\n\u001b[1;32m    210\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    212\u001b[0m     optim\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/class/487/project/coherenceModel.py:209\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m windows, labels \u001b[38;5;129;01min\u001b[39;00m trn_loader:\n\u001b[1;32m    208\u001b[0m     num_itr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 209\u001b[0m     windows \u001b[38;5;241m=\u001b[39m [[\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m window] \u001b[38;5;28;01mfor\u001b[39;00m window \u001b[38;5;129;01min\u001b[39;00m windows]\n\u001b[1;32m    210\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    212\u001b[0m     optim\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def search_param_utterance(wsize):\n",
    "    \"\"\"Experiemnt on different hyper parameters.\"\"\"\n",
    "    learning_rate, weight_decay = get_hyper_parameters()\n",
    "    window_sizes = [wsize]\n",
    "    print(\"learning rate from: {}\\nweight_decay from: {}\\nwindow from: {}\".format(\n",
    "        learning_rate, weight_decay, window_sizes\n",
    "    ))\n",
    "    best_model, best_stats = None, None\n",
    "    best_accuracy, best_lr, best_wd, best_window_size = 0, 0, 0, 0\n",
    "    for lr, wd, window_size in tqdm(itertools.product(learning_rate, weight_decay, window_sizes),\n",
    "                           total=len(learning_rate) * len(weight_decay) * len(window_sizes)):\n",
    "        net = FFNN(window_size, device).to(device)\n",
    "        optim = get_optimizer(net, lr=lr, weight_decay=wd)\n",
    "        model, stats = train_model(net, train_loader, dev_loader, optim, pos_weight=pos_weight, \n",
    "                                   num_epoch=100, collect_cycle=500, device=device, \n",
    "                                   verbose=True, patience=5, stopping_criteria='accuracy')\n",
    "        # print accuracy\n",
    "        print(f\"{(lr, wd, window_size)}: {stats['accuracy']}\")\n",
    "        # update best parameters if needed\n",
    "        if stats['accuracy'] > best_accuracy:\n",
    "            best_accuracy = stats['accuracy']\n",
    "            best_model, best_stats = model, stats\n",
    "            best_lr, best_wd, best_window_size = lr, wd, window_size\n",
    "            torch.save(best_model.state_dict(), 'best_rnn.pt')\n",
    "    print(\"\\n\\nBest learning rate: {}, best weight_decay: {}, best window: {}\".format(\n",
    "        best_lr, best_wd, best_window_size))\n",
    "    print(\"Accuracy: {:.4f}\".format(best_accuracy))\n",
    "    plot_loss(best_stats)\n",
    "    return best_model\n",
    "basic_model = search_param_utterance(wsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final selection: window size 5 with Q = 0.0002\n",
      "Test UAR: 0.7660\n",
      "Test accuracy: 0.7768\n",
      "Test loss: 0.9321\n"
     ]
    }
   ],
   "source": [
    "basic_model = FFNN(5, device)\n",
    "basic_model.load_state_dict(torch.load('best_rnn.pt'))\n",
    "basic_model.eval()\n",
    "basic_model.to(device)\n",
    "uar, accuracy, total_loss = get_validation_performance(\n",
    "    basic_model, \n",
    "    nn.BCEWithLogitsLoss(pos_weight=pos_weight), \n",
    "    test_loader, \n",
    "    device\n",
    ")\n",
    "print(\"Final selection: window size 5 with Q = 0.0002\")\n",
    "print(\"Test UAR: {:.4f}\".format(uar))\n",
    "print(\"Test accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test loss: {:.4f}\".format(total_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
